# è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

## æ¦‚è¦

ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€TOMLãƒ™ãƒ¼ã‚¹ã®è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚`api/core/config_manager.py`ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã‚ˆã‚Šã€å‹•çš„ãªè¨­å®šæ›´æ–°ã€ãƒ›ãƒƒãƒˆãƒªãƒ­ãƒ¼ãƒ‰ã€ç’°å¢ƒå¤‰æ•°ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã€è¨­å®šå±¥æ­´ç®¡ç†ãªã©ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

## ä¸»ãªæ©Ÿèƒ½

### ğŸ”§ çµ±åˆè¨­å®šç®¡ç†
- **TOMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: äººé–“ãŒèª­ã¿ã‚„ã™ã„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
- **Pydanticæ¤œè¨¼**: å‹å®‰å…¨ãªè¨­å®šãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- **ç’°å¢ƒå¤‰æ•°ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰**: ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¨­å®šä¸Šæ›¸ã
- **ãƒ›ãƒƒãƒˆãƒªãƒ­ãƒ¼ãƒ‰**: è¨­å®šå¤‰æ›´ã®è‡ªå‹•æ¤œå‡ºã¨åæ˜ 

### ğŸ“ è¨­å®šå¤‰æ›´ç®¡ç†
- **å¤‰æ›´å±¥æ­´**: å…¨ã¦ã®è¨­å®šå¤‰æ›´ã®è¨˜éŒ²
- **ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½**: ç‰¹å®šæ™‚ç‚¹ã¸ã®è¨­å®šå¾©å…ƒ
- **å¤‰æ›´é€šçŸ¥**: è¨­å®šå¤‰æ›´ã®ã‚µãƒ–ã‚¹ã‚¯ãƒ©ã‚¤ãƒãƒ¼é€šçŸ¥
- **ã‚¤ãƒ³ãƒãƒ¼ãƒˆ/ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**: è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

### ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
- **ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†**: ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†
- **è¨­å®šæ¤œè¨¼**: ä¸æ­£ãªè¨­å®šå€¤ã®æ¤œå‡º
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒ**: ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•å¾©å…ƒæ©Ÿèƒ½

## è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

### åŸºæœ¬è¨­å®š (config.toml)

```toml
[app]
name = "LangChain Chatbot"
version = "1.0.0"
debug = false

[backend]
host = "0.0.0.0"
port = 8000
reload = true

[qdrant]
host = "localhost"
port = 6333
grpc_port = 6334
collection_name = "chatbot_knowledge"

[ollama]
base_url = "http://localhost:11434"
model_name = "nomic-embed-text:latest"

[llm]
api_base = "http://localhost:8000/v1"
api_key = "your-api-key"
model_name = "gpt-3.5-turbo"
temperature = 0.7
max_tokens = 1000
top_p = 1.0
frequency_penalty = 0.0
presence_penalty = 0.0

[embedding]
provider = "ollama"
base_url = "http://localhost:11434"
model_name = "nomic-embed-text:latest"
dimension = 768

[upload]
directory = "./uploads"
max_file_size = 10485760  # 10MB

[security]
secret_key = "your-secret-key"
algorithm = "HS256"
access_token_expire_minutes = 30

[cors]
origins = ["http://localhost:3000"]
```

## ConfigManager ã‚¯ãƒ©ã‚¹ã®ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```python
from api.core.config_manager import config_manager

# è¨­å®šã®å–å¾—
config = config_manager.get_config()

# ç‰¹å®šã®è¨­å®šå€¤ã‚’å–å¾—
llm_model = config_manager.get_value("llm", "model_name")
qdrant_host = config_manager.get_value("qdrant", "host")

# è¨­å®šå€¤ã®æ›´æ–°
result = config_manager.set_value(
    section="llm",
    field="temperature", 
    value=0.8,
    user="admin",
    description="Increase temperature for more creative responses"
)

if result.success:
    print(f"è¨­å®šæ›´æ–°æˆåŠŸ: {result.message}")
else:
    print(f"è¨­å®šæ›´æ–°å¤±æ•—: {result.message}")
```

### è¨­å®šå¤‰æ›´ã®ç›£è¦–

```python
def on_llm_temperature_changed(change):
    print(f"LLMæ¸©åº¦ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ: {change.old_value} -> {change.new_value}")

# å¤‰æ›´ã‚’ã‚µãƒ–ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–
config_manager.subscribe_to_changes("llm", "temperature", on_llm_temperature_changed)

# ã‚µãƒ–ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–è§£é™¤
config_manager.unsubscribe_from_changes("llm", "temperature", on_llm_temperature_changed)
```

### è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ/ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

```python
# è¨­å®šã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
config_manager.export_config("backup_config.toml", format="toml")
config_manager.export_config("backup_config.json", format="json")

# è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
result = config_manager.import_config("new_config.toml", format="toml", merge=True)
```

### å¤‰æ›´å±¥æ­´ã®ç®¡ç†

```python
# å¤‰æ›´å±¥æ­´ã®å–å¾—
history = config_manager.get_change_history()

# ç‰¹å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å±¥æ­´
llm_history = config_manager.get_change_history(section="llm")

# ç›´è¿‘5ä»¶ã®å±¥æ­´
recent_history = config_manager.get_change_history(limit=5)

# ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
import time
target_timestamp = time.time() - 3600  # 1æ™‚é–“å‰
result = config_manager.rollback_to_timestamp(target_timestamp)
```

## ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¨­å®š

### ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ç’°å¢ƒå¤‰æ•°

```bash
# Qdrantè¨­å®š
export QDRANT_HOST="localhost"
export QDRANT_PORT="6333"
export QDRANT_COLLECTION_NAME="chatbot_knowledge"

# LLMè¨­å®š
export OPENAI_API_BASE="http://localhost:8000/v1"
export OPENAI_API_KEY="your-api-key"
export OPENAI_MODEL_NAME="gpt-3.5-turbo"
export OPENAI_TEMPERATURE="0.7"

# åŸ‹ã‚è¾¼ã¿è¨­å®š
export EMBEDDING_PROVIDER="ollama"
export EMBEDDING_BASE_URL="http://localhost:11434"
export EMBEDDING_MODEL_NAME="nomic-embed-text:latest"

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
export SECRET_KEY="your-secret-key"
export ALGORITHM="HS256"
export ACCESS_TOKEN_EXPIRE_MINUTES="30"

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è¨­å®š
export UPLOAD_DIR="./uploads"
export MAX_FILE_SIZE="10485760"

# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®š
export BACKEND_HOST="0.0.0.0"
export BACKEND_PORT="8000"
export BACKEND_RELOAD="true"
```

## APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

è¨­å®šç®¡ç†ã®ãŸã‚ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ã§ã™ï¼š

```python
# è¨­å®šã®å–å¾—
GET /api/config

# è¨­å®šã®æ›´æ–°
POST /api/config/update
{
    "section": "llm",
    "field": "temperature",
    "value": 0.8,
    "description": "Increase temperature"
}

# å¤‰æ›´å±¥æ­´ã®å–å¾—
GET /api/config/history

# è¨­å®šã®ãƒªã‚»ãƒƒãƒˆ
POST /api/config/reset
```

## è¨­å®šãƒ¢ãƒ‡ãƒ«

### ChatbotConfig

```python
@dataclass
class ChatbotConfig:
    app: AppConfig
    backend: BackendConfig
    qdrant: QdrantConfig
    ollama: OllamaConfig
    llm: LLMConfig
    embedding: EmbeddingConfig
    upload: UploadConfig
    security: SecurityConfig
    cors: CorsConfig
    chat: ChatConfig
    database: DatabaseConfig
```

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†
- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã«å«ã‚ã€æ©Ÿå¯†æƒ…å ±ã¯ç’°å¢ƒå¤‰æ•°ã§ç®¡ç†
- é–‹ç™ºç’°å¢ƒã¨æœ¬ç•ªç’°å¢ƒã§åˆ¥ã€…ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
- è¨­å®šå¤‰æ›´å‰ã«å¿…ãšãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ

### 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
- APIã‚­ãƒ¼ã‚„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã¯ç’°å¢ƒå¤‰æ•°ã§ç®¡ç†
- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’é©åˆ‡ã«è¨­å®š
- å¤‰æ›´å±¥æ­´ã‚’ç›£æŸ»

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- è¨­å®šå€¤ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦é »ç¹ãªãƒ•ã‚¡ã‚¤ãƒ«I/Oã‚’é¿ã‘ã‚‹
- å¤‰æ›´é€šçŸ¥ã‚’ä½¿ç”¨ã—ã¦å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã¿æ›´æ–°
- è¨­å®šæ¤œè¨¼ã¯éåŒæœŸã§å®Ÿè¡Œ

### 4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
- ä¸æ­£ãªè¨­å®šå€¤ã¯æ¤œè¨¼ã—ã¦æ‹’å¦
- ã‚¨ãƒ©ãƒ¼æ™‚ã¯è‡ªå‹•çš„ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ä¸€èˆ¬çš„ãªå•é¡Œ

1. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„**
   - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãŒè‡ªå‹•çš„ã«ä½œæˆã•ã‚Œã¾ã™
   - ç’°å¢ƒå¤‰æ•° `CONFIG_PATH` ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã§ãã¾ã™

2. **è¨­å®šã®ãƒ›ãƒƒãƒˆãƒªãƒ­ãƒ¼ãƒ‰ãŒå‹•ä½œã—ãªã„**
   - ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
   - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚’ç¢ºèª

3. **ç’°å¢ƒå¤‰æ•°ãŒåæ˜ ã•ã‚Œãªã„**
   - ç’°å¢ƒå¤‰æ•°ã®åå‰ã¨å€¤ã‚’ç¢ºèª
   - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å†èµ·å‹•ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™

### ãƒ‡ãƒãƒƒã‚°æ–¹æ³•

```python
# ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º
config = config_manager.get_config()
print(config.model_dump())

# è¨­å®šã®æ¤œè¨¼çµæœã‚’ç¢ºèª
validation = config_manager.validate_config()
print(validation)

# å¤‰æ›´å±¥æ­´ã‚’ç¢ºèª
history = config_manager.get_change_history()
for change in history:
    print(f"{change.timestamp}: {change.section}.{change.field} = {change.new_value}")
```

## ãƒ†ã‚¹ãƒˆ

è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆï¼š

```bash
# è¨­å®šç®¡ç†ã®ãƒ†ã‚¹ãƒˆ
pytest tests/test_config_manager.py

# è¨­å®šAPIã®ãƒ†ã‚¹ãƒˆ
pytest tests/test_config_routes.py

# çµ±åˆãƒ†ã‚¹ãƒˆ
pytest tests/test_config_integration.py
```

ã“ã®è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šã€æŸ”è»Ÿã§å®‰å…¨ãªè¨­å®šç®¡ç†ãŒå¯èƒ½ã«ãªã‚Šã€é‹ç”¨ç’°å¢ƒã§ã®è¨­å®šå¤‰æ›´ãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ã€‚